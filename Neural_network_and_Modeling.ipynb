{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30699655",
   "metadata": {},
   "source": [
    "# Fake job Prediction: Investigating the pattern to avoid the job scam\n",
    "\n",
    "# Notebook 5  Neural network and Modeling\n",
    "\n",
    "**Fifth setp: Modeling with Pre-trained word vectors and Neural network**\n",
    "\n",
    "By: Polly Pang\n",
    "\n",
    "In this portion of the notebook, I will use Pre-trained word vectors, convert text column into sparse metrics. And implement traditional Ml models and also Neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b6afd2",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" role=\"tab\" aria-controls=\"home\"> Contents</h3>\n",
    "\n",
    "* [1. Libraries](#1)\n",
    "* [2. Load data](#2)  \n",
    "* [3. Word Embeddings](#3)\n",
    "    - [3.1 Word2Vec](#3.1)\n",
    "    - [3.2 vectorization](#3.2)\n",
    "* [4. Modeling](#3)\n",
    "    - [4.1 oversampling](#3.2)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "* [7. End of Notebook 5](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e211031e",
   "metadata": {},
   "source": [
    "# 1. Libraries <a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "35a154ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as imbPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1e3f1",
   "metadata": {},
   "source": [
    "# 2. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea552e",
   "metadata": {},
   "source": [
    "## 2.1 Target and Feature<a id=\"2.1\"></a>\n",
    "<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec639be1",
   "metadata": {},
   "source": [
    "**plan**\n",
    "- Define X and y, Target :`fraudulent`, Features:`has_salary_range`,`telecommuting`,`has_company_logo`,`has_questions`,and `text`.\n",
    "- split data into test set and reminder set, as I will process Cross-Validation in the follwing part, so I will not split my dataset into train and test.\n",
    "- investigate the distribustion of reminder set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0dd2cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "word_embed_df=joblib.load('data/df_model_full_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcc0c6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_salary_range</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Marketing Intern Marketing We're Food52, and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Commissioning Machinery Assistant (CMA) Blank ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Account Executive - Washington DC Sales Our pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Bill Review Manager Blank SpotSource Solutions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Accounting Clerk Blank Blank Job OverviewApex ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17874</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Account Director - Distribution Sales Vend is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17875</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Payroll Accountant Accounting WebLinc is the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Project Cost Control Staff Engineer - Cost Con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Graphic Designer Blank Blank Nemsia Studios is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17878</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Web Application Developers Engineering Vend is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17879 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       has_salary_range  telecommuting  has_company_logo  has_questions  \\\n",
       "0                     0              0                 1              0   \n",
       "1                     0              0                 1              0   \n",
       "2                     0              0                 1              0   \n",
       "3                     0              0                 1              1   \n",
       "4                     0              0                 0              0   \n",
       "...                 ...            ...               ...            ...   \n",
       "17874                 0              0                 1              1   \n",
       "17875                 0              0                 1              1   \n",
       "17876                 0              0                 0              0   \n",
       "17877                 0              0                 0              1   \n",
       "17878                 0              0                 1              1   \n",
       "\n",
       "       fraudulent                                               text  \n",
       "0               0  Marketing Intern Marketing We're Food52, and w...  \n",
       "1               0  Commissioning Machinery Assistant (CMA) Blank ...  \n",
       "2               0  Account Executive - Washington DC Sales Our pa...  \n",
       "3               0  Bill Review Manager Blank SpotSource Solutions...  \n",
       "4               0  Accounting Clerk Blank Blank Job OverviewApex ...  \n",
       "...           ...                                                ...  \n",
       "17874           0  Account Director - Distribution Sales Vend is ...  \n",
       "17875           0  Payroll Accountant Accounting WebLinc is the e...  \n",
       "17876           0  Project Cost Control Staff Engineer - Cost Con...  \n",
       "17877           0  Graphic Designer Blank Blank Nemsia Studios is...  \n",
       "17878           0  Web Application Developers Engineering Vend is...  \n",
       "\n",
       "[17879 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample of dataset\n",
    "word_embed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1693fa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of word_embed_df is (17879, 6)\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of word_embed_df is {word_embed_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96eab67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17879 entries, 0 to 17878\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   has_salary_range  17879 non-null  int32 \n",
      " 1   telecommuting     17879 non-null  int64 \n",
      " 2   has_company_logo  17879 non-null  int64 \n",
      " 3   has_questions     17879 non-null  int64 \n",
      " 4   fraudulent        17879 non-null  int64 \n",
      " 5   text              17879 non-null  object\n",
      "dtypes: int32(1), int64(4), object(1)\n",
      "memory usage: 768.4+ KB\n"
     ]
    }
   ],
   "source": [
    "word_embed_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa349b7",
   "metadata": {},
   "source": [
    "**Define Target and Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ad9dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X=word_embed_df.drop('fraudulent',axis=1)\n",
    "y=word_embed_df['fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e3670d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of features(X) is (17879, 5),and the shape of y (Target) is (17879,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of features(X) is {X.shape},and the shape of y (Target) is {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1428a38a",
   "metadata": {},
   "source": [
    "**Reminder and test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f5631fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rem,X_test,y_rem,y_test=train_test_split(X,y,test_size=0.3,random_state=5, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc7c2559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_reminder is (12515, 5),and the shape of y_rem is (12515,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of X_reminder is {X_rem.shape},and the shape of y_rem is {y_rem.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "058d01d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_test is (5364, 5),and the shape of y_test is (5364,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of X_test is {X_test.shape},and the shape of y_test is {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f59efc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_salary_range</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Creative Director - Art Blank Kettle is an ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11082</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>CDL Driver Blank ABC Supply Co., Inc. is the n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14188</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Analyst (Marketing) Blank Blank We are lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8280</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Channel Representative Blank Intercom (# is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13924</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Programmatic Media Manager Media Since 1978Our...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       has_salary_range  telecommuting  has_company_logo  has_questions  \\\n",
       "4310                  0              0                 1              1   \n",
       "11082                 0              0                 1              0   \n",
       "14188                 0              0                 1              0   \n",
       "8280                  0              0                 1              1   \n",
       "13924                 0              0                 1              0   \n",
       "\n",
       "                                                    text  \n",
       "4310   Creative Director - Art Blank Kettle is an ind...  \n",
       "11082  CDL Driver Blank ABC Supply Co., Inc. is the n...  \n",
       "14188  Data Analyst (Marketing) Blank Blank We are lo...  \n",
       "8280   Channel Representative Blank Intercom (# is a ...  \n",
       "13924  Programmatic Media Manager Media Since 1978Our...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaf366b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rem.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a895360b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_salary_range</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8222</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>eCommerce Specialist / Database Management for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Solution Engineer Blank Declara is focused on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17171</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales Representative for Home Improvement Blan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9164</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Customer Service Specialist Interpreting Servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9454</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Customer Service Associate - Records Blank Nov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       has_salary_range  telecommuting  has_company_logo  has_questions  \\\n",
       "8222                  1              0                 1              0   \n",
       "1560                  0              0                 1              1   \n",
       "17171                 1              0                 0              1   \n",
       "9164                  0              0                 1              1   \n",
       "9454                  0              0                 1              0   \n",
       "\n",
       "                                                    text  \n",
       "8222   eCommerce Specialist / Database Management for...  \n",
       "1560   Solution Engineer Blank Declara is focused on ...  \n",
       "17171  Sales Representative for Home Improvement Blan...  \n",
       "9164   Customer Service Specialist Interpreting Servi...  \n",
       "9454   Customer Service Associate - Records Blank Nov...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0f38cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f08197",
   "metadata": {},
   "source": [
    "- X_rem and X_test have same features, and y_test and y_rem contains only 2 result.\n",
    "- 2 Reminder sets and test stes have same number of rows.\n",
    "- Now I have my reminder and test set ready."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ea260",
   "metadata": {},
   "source": [
    "# 3. Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d5600",
   "metadata": {},
   "source": [
    "## 3.1 Word2Vec<a id=\"2.1\"></a>\n",
    "<a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\">Go to TOC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b21451b",
   "metadata": {},
   "source": [
    "**Plan**\n",
    "- Define function text_process(), apply to X_rem and X_test\n",
    "- Define function sentence2vec()\n",
    "- Define column transfor\n",
    "- Create sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496d3bb1",
   "metadata": {},
   "source": [
    "**Function text_process()**\n",
    "\n",
    "**What does the function do**\n",
    "- lowercase all the text\n",
    "- Get rid of extra blank\n",
    "- Take out of stopwords\n",
    "- Take out puncuations\n",
    "- Stemming\n",
    "- Combine all the text back to a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7401b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init stemmer\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "# make tokens\n",
    "def text_process(text):\n",
    "    non_pun=''.join([w for w in text.lower() if w not in string.punctuation])\n",
    "\n",
    "    lst_words=non_pun.split(' ')\n",
    "    #print(lst_words)\n",
    "    # remove stop words and stem\n",
    "    lst_out=[]\n",
    "    for w in lst_words:\n",
    "        if (w not in stopwords.words('english')) and (w != \"\"):\n",
    "            stemmed_word = stemmer.stem(w)\n",
    "            lst_out.append(stemmed_word)\n",
    "    # combine list into sentence\n",
    "            sentence = ' '.join(lst_out)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0da8cc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'market intern market food52 weve creat groundbreak awardwin cook site support connect celebr home cook give everyth need one placew top editori busi engin team focus use technolog find new better way connect peopl around specif food interest offer superb highli curat inform food cook attract talent home cook contributor countri also publish wellknown profession like mario batali gwyneth paltrow danni meyer partnership whole food market random housefood52 name best food websit jame beard foundat iacp featur new york time npr pando daili techcrunch today showwer locat chelsea new york citi food52 fastgrow jame beard awardwin onlin food commun crowdsourc curat recip hub current interview full parttim unpaid intern work small team editor execut develop new york citi headquartersreproduc andor repackag exist food52 content number partner site huffington post yahoo buzzfe variou content manag systemsresearch blog websit provis food52 affili programassist daytoday affili program support screen affili assist affili inquiriessupport pr amp event neededhelp offic administr work file mail prepar meetingswork develop document bug suggest improv sitesupport market execut staff experi content manag system major plu blog countsfamiliar food52 editori voic aestheticlov food appreci import home cook cook seasonsmeticul editor perfectionist obsess attent detail madden typo broken link delight find fix themcheer pressureexcel commun skillsa multitask juggler respons big smallinterest engag social media like twitter facebook pinterestlov problemsolv collabor drive food52 forwardthink big pictur pitch nitti gritti run small compani dish shop administr supportcomfort realiti work startup call even weekend work long hour blank internship blankblank market us'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test result\n",
    "text_process(X_rem['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40e2b77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Marketing Intern Marketing We're Food52, and we've created a groundbreaking and award-winning cooking site. We support, connect, and celebrate home cooks, and give them everything they need in one place.We have a top editorial, business, and engineering team. We're focused on using technology to find new and better ways to connect people around their specific food interests, and to offer them superb, highly curated information about food and cooking. We attract the most talented home cooks and contributors in the country; we also publish well-known professionals like Mario Batali, Gwyneth Paltrow, and Danny Meyer. And we have partnerships with Whole Foods Market and Random House.Food52 has been named the best food website by the James Beard Foundation and IACP, and has been featured in the New York Times, NPR, Pando Daily, TechCrunch, and on the Today Show.We're located in Chelsea, in New York City. Food52, a fast-growing, James Beard Award-winning online food community and crowd-sourced and curated recipe hub, is currently interviewing full- and part-time unpaid interns to work in a small team of editors, executives, and developers in its New York City headquarters.Reproducing and/or repackaging existing Food52 content for a number of partner sites, such as Huffington Post, Yahoo, Buzzfeed, and more in their various content management systemsResearching blogs and websites for the Provisions by Food52 Affiliate ProgramAssisting in day-to-day affiliate program support, such as screening affiliates and assisting in any affiliate inquiriesSupporting with PR &amp; Events when neededHelping with office administrative work, such as filing, mailing, and preparing for meetingsWorking with developers to document bugs and suggest improvements to the siteSupporting the marketing and executive staff Experience with content management systems a major plus (any blogging counts!)Familiar with the Food52 editorial voice and aestheticLoves food, appreciates the importance of home cooking and cooking with the seasonsMeticulous editor, perfectionist, obsessive attention to detail, maddened by typos and broken links, delighted by finding and fixing themCheerful under pressureExcellent communication skillsA+ multi-tasker and juggler of responsibilities big and smallInterested in and engaged with social media like Twitter, Facebook, and PinterestLoves problem-solving and collaborating to drive Food52 forwardThinks big picture but pitches in on the nitty gritty of running a small company (dishes, shopping, administrative support)Comfortable with the realities of working for a startup: being on call on evenings and weekends, and working long hours Blank Other Internship BlankBlank Marketing US\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare with the orignal text\n",
    "X_rem['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e336bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_rem pre-process \n",
    "X_rem_stem=X_rem.copy()\n",
    "\n",
    "X_rem_stem['text']=X_rem_stem['text'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d4b180c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rem_stem.shape==X_rem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0487f70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test pre-process \n",
    "X_test_stem=X_test.copy()\n",
    "X_test_stem['text']=X_test_stem['text'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8729dca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape==X_test_stem.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f470f",
   "metadata": {},
   "source": [
    "- X_rem and X_test has been transfered, moving forward I will keep NLP precoess using X_test_stem and X_rem_stem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b7f328",
   "metadata": {},
   "source": [
    "**customized vectorizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10567e19",
   "metadata": {},
   "source": [
    "- Word2Vec, you need to down load and unzip the pre_trained word vectors. load pretrained vectors: we will use [LexVec](https://github.com/alexandres/lexvec) and Wikipedia.\n",
    "- This is a 300-dimensional embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "559772f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('word_vectors/lexvec-wikipedia-word-vectors', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4cc84466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2vec(text):\n",
    "    \"\"\"\n",
    "    Embed a sentence by averaging the word vectors of the tokenized text. \n",
    "    Out-of-vocabulary words are replaced by the zero-vector.\n",
    "    -----\n",
    "    \n",
    "    Input: text (string)\n",
    "    Output: embedding vector (np.array)\n",
    "    \"\"\"\n",
    "    tokenized = simple_preprocess(text)\n",
    "    \n",
    "    word_embeddings = [np.zeros(300)]\n",
    "    for word in tokenized:\n",
    "        # if the word is in the model then embed\n",
    "        if word in model:\n",
    "            vector = model[word]\n",
    "        # add zeros for out-of-vocab words\n",
    "        else:\n",
    "            vector = np.zeros(300)\n",
    "            \n",
    "        word_embeddings.append(vector)\n",
    "    \n",
    "    # average the word vectors\n",
    "    sentence_embedding = np.stack(word_embeddings).mean(axis=0)\n",
    "    \n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe11833d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.73303677e-03, -7.40721906e-03,  1.96714861e-02, -9.62654653e-03,\n",
       "       -7.61171243e-03,  7.10465100e-02,  2.79783374e-03, -3.44043646e-02,\n",
       "        2.67091537e-02,  3.47746526e-02,  3.64276721e-02,  4.86087006e-02,\n",
       "       -5.14526681e-02,  5.95221453e-02,  3.72461983e-02, -7.26838076e-03,\n",
       "       -2.58509070e-02,  1.05571504e-02,  1.63256722e-02,  2.45892592e-02,\n",
       "       -2.23805102e-02, -1.03946277e-02,  3.08614728e-02,  2.79396841e-02,\n",
       "       -3.21179997e-02,  2.59392796e-02,  6.13525187e-02,  6.66009756e-02,\n",
       "        8.12814498e-02, -9.03423099e-03, -6.22478060e-02,  1.34164980e-02,\n",
       "        1.39349112e-02, -1.21182504e-02,  6.12421055e-03,  4.17263240e-02,\n",
       "        1.42471214e-02, -5.70988515e-04, -2.02543078e-02,  5.34754635e-03,\n",
       "        4.08871904e-02,  6.40502865e-03, -4.73126478e-02, -7.77524050e-02,\n",
       "       -1.58924088e-02, -3.13673809e-02,  3.28009921e-02, -1.21536515e-02,\n",
       "       -3.01963932e-02, -5.86122256e-03,  2.21079427e-02,  2.29700792e-03,\n",
       "       -3.03853055e-03,  3.96353019e-03, -4.42204048e-02,  1.57283600e-02,\n",
       "       -5.05864819e-03,  2.78710556e-02, -1.02716395e-02, -2.80501209e-03,\n",
       "        1.65872876e-03, -3.75584014e-02, -6.49008160e-04,  4.16275381e-02,\n",
       "        1.80152388e-02,  8.44019111e-02, -1.17866150e-02, -1.14091379e-02,\n",
       "        4.20767492e-02,  1.02564615e-02,  4.44633194e-02,  4.32129714e-02,\n",
       "       -1.15927775e-02,  4.67524256e-02, -4.95560486e-02,  3.17853605e-02,\n",
       "        3.32782507e-02, -3.41542753e-02,  4.20375302e-02, -6.99870822e-04,\n",
       "       -2.85661144e-03,  3.41618423e-02, -3.78657738e-02,  2.65487366e-02,\n",
       "       -3.53626763e-02,  1.48444931e-03, -5.84048015e-02, -6.36928361e-03,\n",
       "       -6.58726680e-02, -5.00130728e-02, -2.41725382e-02, -3.94797249e-02,\n",
       "        7.72302045e-03,  2.14122350e-02,  1.56342837e-02, -3.50100563e-02,\n",
       "       -3.95903124e-02,  1.55408460e-02, -2.32668987e-02,  1.18518420e-02,\n",
       "        2.69083111e-02,  6.57801702e-02, -2.95390119e-02,  6.61836064e-03,\n",
       "        2.00162026e-02, -3.67816635e-02, -4.03475255e-02, -1.95818059e-02,\n",
       "       -1.21903601e-02,  1.72530646e-02,  2.85218183e-02,  4.83889473e-02,\n",
       "        5.94670814e-02,  3.46116353e-02,  2.86958746e-02, -3.12540691e-02,\n",
       "        2.16449959e-02, -1.87791059e-02, -2.25995793e-02, -7.71865670e-02,\n",
       "        1.66540563e-02,  4.05761584e-02, -3.84822549e-02,  5.52955708e-02,\n",
       "        3.60513191e-02, -4.03114651e-02,  2.63017650e-02,  2.31752267e-02,\n",
       "       -4.62275716e-02,  2.51909393e-02,  2.33631821e-02,  2.33437454e-02,\n",
       "       -6.70149875e-04, -1.72589154e-02, -3.75522273e-02, -9.17720909e-04,\n",
       "       -6.97686481e-02, -6.37113038e-02,  5.72858059e-02,  6.24366519e-02,\n",
       "        2.39142839e-02, -3.31843889e-02,  1.10939071e-02, -2.18459494e-03,\n",
       "        3.73589518e-02, -9.47134451e-03,  2.51789872e-03, -9.08381383e-03,\n",
       "       -6.53199145e-02,  2.04717562e-02, -6.36755304e-02,  1.24953118e-02,\n",
       "       -4.77523160e-02, -4.41864052e-02, -4.80610141e-03,  1.26335382e-02,\n",
       "       -3.86268790e-03,  2.74667489e-02, -4.19288735e-03, -2.46593519e-03,\n",
       "        5.62302102e-02, -4.53644775e-02, -4.75880973e-03,  6.13439682e-02,\n",
       "        1.54184224e-03, -2.93566116e-02,  3.42749274e-02, -4.06120483e-02,\n",
       "       -2.73979149e-02,  1.96447292e-02,  2.42238988e-02,  5.83313603e-02,\n",
       "        7.65917446e-02,  4.27093038e-02,  5.15150127e-04,  6.79396775e-03,\n",
       "       -9.23764770e-03, -1.01143154e-02, -1.21429717e-02, -1.91317815e-02,\n",
       "        7.73642934e-03,  5.84752186e-02, -5.19726301e-03, -3.34883078e-02,\n",
       "        1.06097771e-02,  2.21071415e-02, -3.68400529e-02,  5.08319228e-02,\n",
       "       -6.00463517e-03, -3.72513325e-02, -2.25720529e-02,  9.70951396e-03,\n",
       "        2.74910525e-02, -3.85040200e-02,  3.90872555e-02, -6.34551895e-03,\n",
       "        7.62818379e-04,  3.12025458e-02,  1.97861170e-02, -6.51361703e-02,\n",
       "       -3.23078147e-03,  3.23441339e-02,  1.83710363e-02,  2.78033729e-02,\n",
       "       -6.59930334e-03, -1.95116521e-02, -9.88559493e-03, -6.82036834e-03,\n",
       "       -4.94472897e-03,  2.75407286e-02, -9.90654218e-03,  5.20020622e-03,\n",
       "        2.46427171e-02, -9.58842925e-03, -4.58287083e-02,  5.34068990e-02,\n",
       "        2.91440811e-02, -4.23244373e-02,  3.84451622e-02, -4.99455753e-02,\n",
       "       -2.22358216e-02,  2.54084489e-02, -3.16608259e-02,  3.40818907e-02,\n",
       "       -5.04451661e-02, -4.54876597e-02,  4.73371536e-02, -6.69248547e-03,\n",
       "        2.12283605e-02, -3.31768586e-02,  1.02384980e-02, -7.95574088e-03,\n",
       "       -8.39403676e-03, -1.06138056e-02,  4.64014732e-02,  1.72728253e-02,\n",
       "        1.65219560e-02,  1.92024170e-02, -1.69415668e-02, -3.13999556e-03,\n",
       "        3.98305910e-02, -5.55029633e-02, -2.97191861e-03, -6.24175561e-05,\n",
       "        1.58049879e-02,  4.84402949e-02, -3.25810407e-02, -4.92860044e-02,\n",
       "       -2.83023520e-02, -1.43410644e-02,  1.66438704e-02, -4.32236428e-02,\n",
       "        1.98079744e-03, -4.77228054e-02,  7.86000856e-02, -3.53264940e-02,\n",
       "       -2.84337766e-02, -3.82795868e-02,  4.40924289e-02, -2.00570021e-03,\n",
       "       -3.61030003e-02,  3.50310205e-02, -6.31870297e-04, -1.17109961e-02,\n",
       "       -3.64997174e-03, -2.41858303e-02,  3.36507736e-02,  2.89040286e-02,\n",
       "        5.32041135e-02, -2.20460567e-02, -2.44538780e-02,  4.18870849e-02,\n",
       "        5.69188543e-02,  4.91121499e-03, -4.20184975e-03, -1.58323326e-02,\n",
       "       -9.39673703e-03, -6.71695914e-03, -4.78232352e-02,  1.14018143e-02,\n",
       "       -1.72505062e-02, -1.01440688e-02,  7.16295792e-04, -5.16316205e-03,\n",
       "       -1.05390731e-02, -1.21337047e-02,  2.54566721e-02,  3.06098822e-02,\n",
       "       -6.18839924e-02, -3.25950851e-02,  1.84137854e-02, -5.72200114e-02,\n",
       "       -1.60633243e-02, -7.00598506e-02, -3.35707740e-03,  4.14168911e-02,\n",
       "       -9.73145325e-03, -1.08634777e-02, -5.58942900e-03,  1.39117775e-02])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run test on function sentence2vec, funtion sentence2vec will vectorlize a chunk of words and make them into vectors.\n",
    "sentence2vec(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a254106e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  300-dimensional\n",
    "sentence2vec(test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359017c4",
   "metadata": {},
   "source": [
    "**column tranformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0ab96a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns are: ['has_salary_range', 'telecommuting', 'has_company_logo', 'has_questions']\n"
     ]
    }
   ],
   "source": [
    "numerical = list(X_rem_stem.select_dtypes('number').columns)\n",
    "print(f\"Numerical columns are: {numerical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6ed97dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text columns is: ['text']\n"
     ]
    }
   ],
   "source": [
    "text = list(X_rem_stem.select_dtypes('object').columns)\n",
    "print(f\"text columns is: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "62900f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the column transformations list + columns to which to apply\n",
    "col_transforms_nn = [('num','passthrough', numerical),\n",
    "                ('sentence2vec', sentence2vec, 'text')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b4a569ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the column transformer\n",
    "col_trans_nn = ColumnTransformer(col_transforms_nn,remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cffe05f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All estimators should implement fit and transform, or can be 'drop' or 'passthrough' specifiers. '<function sentence2vec at 0x000001A9F90160D0>' (type <class 'function'>) doesn't.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# fit\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#pipeline.fit_transform(X_rem_stem)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mcol_trans_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_rem_stem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:657\u001b[0m, in \u001b[0;36mColumnTransformer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit all transformers using X.\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \n\u001b[0;32m    641\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;124;03m    This estimator.\u001b[39;00m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;66;03m# we use fit_transform to make sure to set sparse_output_ (for which we\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;66;03m# need the transformed data) to have consistent output type in predict\u001b[39;00m\n\u001b[1;32m--> 657\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:686\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;66;03m# set n_features_in_ attribute\u001b[39;00m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 686\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_transformers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_column_callables(X)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:358\u001b[0m, in \u001b[0;36mColumnTransformer._validate_transformers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[0;32m    356\u001b[0m     t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m ):\n\u001b[1;32m--> 358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll estimators should implement fit and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform, or can be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecifiers. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (t, \u001b[38;5;28mtype\u001b[39m(t))\n\u001b[0;32m    362\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: All estimators should implement fit and transform, or can be 'drop' or 'passthrough' specifiers. '<function sentence2vec at 0x000001A9F90160D0>' (type <class 'function'>) doesn't."
     ]
    }
   ],
   "source": [
    "# fit\n",
    "#pipeline.fit_transform(X_rem_stem)\n",
    "col_trans_nn.fit(X_rem_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5da1b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e27a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822d24ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
